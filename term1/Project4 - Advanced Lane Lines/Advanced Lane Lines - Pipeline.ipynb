{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Project - Advanced Lane Lines (Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib inline\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# prepare object points\n",
    "nx = 9 # number of inside corners in x\n",
    "ny = 6 # number of inside corners in y\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "cal_images_set = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "def calibrate(image_set, objpoints, imgpoints, objp, img_size):\n",
    "    \n",
    "    for cal_image_name in image_set:\n",
    "        cal_image = cv2.imread(cal_image_name)\n",
    "        gray_image = cv2.cvtColor(cal_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        ret, corners = cv2.findChessboardCorners(gray_image, (nx,ny), None)\n",
    "        if ret == True:\n",
    "            cal_image = cv2.drawChessboardCorners(cal_image, (nx, ny), corners, ret)\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            cv2.imwrite(\"output_images/\" + cal_image_name[11:-4] + \"_with_chessboardcorners.jpg\", cal_image)\n",
    "            #plt.imshow(cal_image)\n",
    "        else: \n",
    "            cv2.imwrite(\"output_images/\" + cal_image_name[11:-4] + \"_with_no_chessboardcorners.jpg\", cal_image)\n",
    "\n",
    "    sample_image = cv2.imread('camera_cal/calibration2.jpg')\n",
    "    imshape = sample_image.shape\n",
    "    img_size = (sample_image.shape[1], sample_image.shape[0])            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    return mtx, dist\n",
    "\n",
    "def apply_threshold(image):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    # Note: img is the undistorted image\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Grayscale image\n",
    "    # NOTE: we already saw that standard grayscaling lost color information for the lane lines\n",
    "    # Explore gradients in other colors spaces / color channels to see what might work better\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    thresh_min = 25\n",
    "    thresh_max = 150\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 75\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    return combined_binary\n",
    "\n",
    "def get_transform_info(image_shape):\n",
    "    offset = 100\n",
    "    img_size = (image_shape[1], image_shape[0])\n",
    "\n",
    "    src = np.float32(\n",
    "      [[(img_size[0] / 2) - 55,     img_size[1] / 2 + offset],\n",
    "      [((img_size[0] / 6) - 10),    img_size[1]],\n",
    "       [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "       [(img_size[0] / 2 + 55),     img_size[1] / 2 + offset]])\n",
    "    dst = np.float32(\n",
    "      [[(img_size[0] / 4),     0],\n",
    "       [(img_size[0] / 4),     img_size[1]],\n",
    "       [(img_size[0] * 3 / 4), img_size[1]],\n",
    "       [(img_size[0] * 3 / 4), 0]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    binary_warped = cv2.warpPerspective(combined_image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return M, Minv, binary_warped\n",
    "\n",
    "def process_test_frame(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 15\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2)\n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    return out_img, nonzerox, nonzeroy, left_lane_inds, right_lane_inds, left_fitx, right_fitx, ploty, leftx, lefty, rightx, righty, left_fit, right_fit\n",
    "\n",
    "\n",
    "def process_first_frame(binary_warped):\n",
    "    out_img, nonzerox, nonzeroy, left_lane_inds, right_lane_inds, left_fitx, right_fitx, ploty, leftx, lefty, rightx, righty, left_fit, right_fit = process_test_frame(binary_warped)\n",
    "    return out_img, left_fitx, right_fitx, ploty, left_fit, right_fit\n",
    "\n",
    "def process_next_frame(binary_warped, left_fit, right_fit):\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    return out_img, margin, left_fit, right_fit, ploty, left_fitx, right_fitx\n",
    "\n",
    "def calculate_radius_of_curvature_meters(binary_warped, left_fitx, right_fitx, ploty):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = binary_warped.shape[0]\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Calculate position of vehicle\n",
    "    left_lane_poly = left_fit_cr[0]*y_eval*ym_per_pix**2 + left_fit_cr[1]*y_eval*ym_per_pix + left_fit_cr[2]\n",
    "    right_lane_poly = right_fit_cr[0]*y_eval*ym_per_pix**2 + right_fit_cr[1]*y_eval*ym_per_pix + right_fit_cr[2]\n",
    "    lane_center = (left_lane_poly +  right_lane_poly) / 2\n",
    "    lane_width = right_lane_poly - left_lane_poly\n",
    "    vehicle_center = binary_warped.shape[1] * xm_per_pix / 2\n",
    "    vehicle_position = lane_center - vehicle_center\n",
    "    \n",
    "    return left_curverad, right_curverad, vehicle_position, lane_width\n",
    "\n",
    "#left_curverad, right_curverad, vehicle_position = calculate_radius_of_curvature_meters(binary_warped, left_fitx, right_fitx, ploty)\n",
    "#print(left_curverad, 'm', right_curverad, 'm', vehicle_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit = 0\n",
    "right_fit = 0\n",
    "ploty = 0\n",
    "left_fitx = 0\n",
    "right_fitx = 0\n",
    "mtx = []\n",
    "dist = []\n",
    "out_img = []\n",
    "lw = []\n",
    "\n",
    "# The guts of finding lane lines and tracking    \n",
    "def track_lane_lines_pipeline(image, image_count):\n",
    "    global left_fit\n",
    "    global right_fit\n",
    "    global ploty\n",
    "    global left_fitx\n",
    "    global right_fitx\n",
    "    global mtx\n",
    "    global dist\n",
    "    global out_img\n",
    "    image_shape = image.shape\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    \n",
    "    offset = 100\n",
    "    img_size = (image_shape[1], image_shape[0])\n",
    "\n",
    "    src = np.float32(\n",
    "      [[(img_size[0] / 2) - 55,     img_size[1] / 2 + offset],\n",
    "      [((img_size[0] / 6) - 10),    img_size[1]],\n",
    "       [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "       [(img_size[0] / 2 + 55),     img_size[1] / 2 + offset]])\n",
    "    dst = np.float32(\n",
    "      [[(img_size[0] / 4),     0],\n",
    "       [(img_size[0] / 4),     img_size[1]],\n",
    "       [(img_size[0] * 3 / 4), img_size[1]],\n",
    "       [(img_size[0] * 3 / 4), 0]])    \n",
    "\n",
    "    if image_count == 0:\n",
    "        img_size = (image.shape[1], image.shape[0])\n",
    "        mtx, dist = calibrate(cal_images_set, objpoints, imgpoints, objp, img_size)    \n",
    "    \n",
    "    undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    combined = apply_threshold(undistorted)\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    binary_warped = cv2.warpPerspective(combined, M, (image_shape[1], image_shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    if image_count == 0:\n",
    "        out_img, left_fitx, right_fitx, ploty, left_fit, right_fit = process_first_frame(binary_warped)\n",
    "        print(\"Processed first frame\")\n",
    "    else:\n",
    "        out_img, margin, left_fit, right_fit, ploty, left_fitx, right_fitx = process_next_frame(binary_warped, left_fit, right_fit)\n",
    "\n",
    "    left_curverad, right_curverad, vehicle_position, lane_width = calculate_radius_of_curvature_meters(binary_warped, left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    if lane_width > 3.936 or lane_width < 2.624:\n",
    "        #print(lane_width,\"m\", image_count)\n",
    "        out_img, left_fitx, right_fitx, ploty, left_fit, right_fit = process_first_frame(binary_warped)\n",
    "        left_curverad, right_curverad, vehicle_position, lane_width = calculate_radius_of_curvature_meters(binary_warped, left_fitx, right_fitx, ploty)\n",
    "        if lane_width > 3.936 or lane_width < 2.624:\n",
    "            lw.append(lane_width)\n",
    "   \n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image_shape[1], image_shape[0]), flags=cv2.INTER_LINEAR) \n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # using cv2 for drawing text in diagnostic pipeline.\n",
    "    position_of_vehicle = \"left\" if vehicle_position < 0 else \"right\"\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    middlepanel = np.zeros((360, 1280, 3), dtype=np.uint8)\n",
    "    cv2.putText(middlepanel, 'Radius of Curvature (Left) = %dm' % left_curverad, (30, 60), font, 3, (255,0,0), 2)\n",
    "    cv2.putText(middlepanel, 'Radius of Curvature (Right) = %dm' % right_curverad, (30, 100), font, 3, (255,0,0), 2)\n",
    "    cv2.putText(middlepanel, 'Vehicle is %.2fm %s of center' % (np.abs(vehicle_position), position_of_vehicle), (30, 140), font, 3, (255,0,0), 2)\n",
    "    cv2.putText(middlepanel, 'Lane Width %.2fm' % (lane_width), (30, 180), font, 3, (255,0,0), 2)\n",
    "    cv2.putText(middlepanel, 'Frame Count %d' % image_count, (30, 220), font, 3, (255,0,0), 2)\n",
    "\n",
    "    # from the forums that my 1st reviewer pointed me to for debugging\n",
    "    # assemble the screen example\n",
    "    diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "    diagScreen[0:720, 0:1280] = result\n",
    "    diagScreen[0:240, 1280:1600] = cv2.resize(image, (320,240), interpolation=cv2.INTER_AREA) \n",
    "    diagScreen[0:240, 1600:1920] = cv2.resize(undistorted, (320,240), interpolation=cv2.INTER_AREA)\n",
    "    diagScreen[240:480, 1280:1600] = cv2.resize(color_warp, (320,240), interpolation=cv2.INTER_AREA)\n",
    "    diagScreen[240:480, 1600:1920] = cv2.resize(newwarp, (320,240), interpolation=cv2.INTER_AREA)*4\n",
    "    diagScreen[600:1080, 1280:1920] = cv2.resize(out_img, (640,480), interpolation=cv2.INTER_AREA)*4\n",
    "    diagScreen[720:1080, 0:1280] = middlepanel\n",
    "\n",
    "    return diagScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_count = 0\n",
    "def process_image(image):\n",
    "    global image_count\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    result = track_lane_lines_pipeline(image, image_count)\n",
    "    image_count += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed first frame\n",
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [04:44<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "video_input = \"project_video.mp4\"\n",
    "#video_output = 'challenge_video_output.mp4'\n",
    "#video_input = \"challenge_video.mp4\"\n",
    "\n",
    "#challenge_video.mp4\n",
    "clip1 = VideoFileClip(video_input)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "The main problem I ran into was that I should have started with implementing a rough pipeline after completing the individual stages. I spent too much time trying to perfect which values to use for the tuning parameters (thresholds, margin, nwindows, etc.).\n",
    "\n",
    "My pipeline performs well on the project video, but not as well on the other two videos where the lines may not be as prevalent or too curvy. Other areas where the pipeline would likely need tuning is scenarios where the contrast is hard to distinguish. Examples would be stormy weather with heavy rain downpour, extremely foggy near coastal areas, heavy snow or dimly lit roads at night.\n",
    "\n",
    "Areas to improve my pipeline, I would focus on different theshold techniques with Sobel or other methods not discussed in the lectures or the convolution method for processing the images.\n",
    "\n",
    "## Follow-up discussion\n",
    "\n",
    "Improvements made after the first submission:\n",
    "- In Project4 - Individual Components, I corrected the displaying of images from BGR to RGB.\n",
    "- Corrected curvature of radius method by breaking calculation into pieces and properly using 2nd order polynomial, center of image on horizontal axis and lane center\n",
    "- Added diag window thanks to 1st reviewer feedback\n",
    "- Corrected extreme values for frames though could still be improved. I did manage to reduce it, but fundamentally I would need to do more work on apply_threshold method because it comes down to noise in the Sobel image. Within my pipeline, I took the measurement of the lane width and took the mean of at the samples to arrive at 3.28m (although it should be 3.7m). From there I added a buffer that if it's between .8 and 1.2 of the mean to continue in the pipeline. Otherwise to reprocess the sample completely for the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
